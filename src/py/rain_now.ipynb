{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "\n",
    "class Meteorological:\n",
    "    def __init__(self, year, place):\n",
    "        self.year = year\n",
    "        self.place = place\n",
    "        self.url = ''\n",
    "        self.now_rain_url = ''\n",
    "        self.place_codeA = 0\n",
    "        self.place_codeB = 0\n",
    "        self.start = 0\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        fname = \"../../config/meteorological.json\"\n",
    "        with open(fname, \"r\") as f:\n",
    "            cfg = json.load(f)\n",
    "\n",
    "        index = cfg['place_name'].index(self.place)\n",
    "        self.place_codeA = str(cfg['place_codeA'][index])\n",
    "        self.place_codeB = str(cfg['place_codeB'][index])\n",
    "        self.url = cfg['url']\n",
    "        self.now_rain_url = cfg['now_rain_url']\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def csv_out(self, data):\n",
    "        #都市ごとにデータをファイルを新しく生成して書き出す。(csvファイル形式。名前は都市名)\n",
    "        with open(self.place + '.csv', 'w') as file:\n",
    "            writer = csv.writer(file, lineterminator='\\n')\n",
    "            writer.writerows(data)\n",
    "\n",
    "\n",
    "    def all_data(self):\n",
    "        all_list = [['年月日', '陸の平均気圧(hPa)', '海の平均気圧(hPa)', '降水量(mm)', '平均気温(℃)', '平均湿度(%)', '平均風速(m/s)', '日照時間(h)']]\n",
    "        self.get_config()\n",
    "\n",
    "        print(self.place)\n",
    "        print(self.year)\n",
    "\n",
    "        for month in range(1,13):\n",
    "            #2つの都市コードと年と月を当てはめる。\n",
    "            r = requests.get(self.url%(self.place_codeA, self.place_codeB, self.year, month))\n",
    "            r.encoding = r.apparent_encoding\n",
    "\n",
    "            # 対象である表をスクレイピング。\n",
    "            soup = BeautifulSoup(r.text)\n",
    "            rows = soup.findAll('tr',class_='mtx') #タグ指定してclass名を指定するみたい。\n",
    "\n",
    "            # 表の最初の1~4行目はカラム情報なのでスライスする。(indexだから初めは0だよ)\n",
    "            # 【追記】2020/3/11 申し訳ございません。間違えてました。\n",
    "            rows = rows[4:]\n",
    "\n",
    "            # 1日〜最終日までの１行を網羅し、取得します。\n",
    "            for row in rows:\n",
    "                data = row.findAll('td')\n",
    "\n",
    "                #１行の中には様々なデータがあるので全部取り出す。\n",
    "                # ★ポイント\n",
    "                rowData = [] #初期化\n",
    "                rowData.append(str(self.year) + \"/\" + str(month) + \"/\" + str(data[0].string))\n",
    "                rowData.append(str2float(data[1].string))\n",
    "                rowData.append(str2float(data[2].string))\n",
    "                rowData.append(str2float(data[3].string))\n",
    "                rowData.append(str2float(data[6].string))\n",
    "                rowData.append(str2float(data[9].string))\n",
    "                rowData.append(str2float(data[11].string))\n",
    "                rowData.append(str2float(data[16].string))\n",
    "\n",
    "                #次の行にデータを追加\n",
    "                all_list.append(rowData)\n",
    "\n",
    "        self.csv_out(all_list)\n",
    "\n",
    "        print('end')\n",
    "\n",
    "\n",
    "    def now_rain(self):\n",
    "        # 全国表示なため、たくさん取ってしまう\n",
    "        # 保留\n",
    "        self.get_config()\n",
    "        now_list = [['都道府県', '市町村', '地点', '現在値(mm)']]\n",
    "        r = requests.get(self.now_rain_url + str(self.place_codeA))\n",
    "        r.encoding = r.apparent_encoding\n",
    "\n",
    "        # 対象である表をスクレイピング。\n",
    "        soup = BeautifulSoup(r.text)\n",
    "        rows = soup.findAll('tr',class_='mtx') #タグ指定してclass名を指定するみたい。\n",
    "\n",
    "#         print(rows)\n",
    "\n",
    "        print('scraping_end')\n",
    "\n",
    "\n",
    "    def past_rain(self):\n",
    "        self.get_config()\n",
    "        self.place_codeB = '00'\n",
    "        month = '9'\n",
    "        day = '9'\n",
    "        r = requests.get(self.url%(self.place_codeA, self.place_codeB, self.year, month, day))\n",
    "        r.encoding = r.apparent_encoding\n",
    "\n",
    "            # 対象である表をスクレイピング。\n",
    "        soup = BeautifulSoup(r.text)\n",
    "        rows = soup.findAll('tr',class_='mtx')\n",
    "        print(rows)\n",
    "\n",
    "\n",
    "    def time_set(self):\n",
    "        self.start = time.time()\n",
    "        print(\"start_time:{:.2f}\".format(self.start) + \"[sec]\")\n",
    "\n",
    "\n",
    "    def time_get(self):\n",
    "        elapsed_time = time.time() - self.start\n",
    "        print(\"elapsed_time:{:.2f}\".format(elapsed_time) + \"[sec]\")\n",
    "        return elapsed_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Meteorological(2019, '高知')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time:1607416453.15[sec]\n",
      "elapsed_time:0.00[sec]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00013709068298339844"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.time_set()\n",
    "m.time_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
